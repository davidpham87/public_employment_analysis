\section{Theory}\label{Theory}

This section synthesizes three papers used as theoretical background to run our
analysis. These are:

\begin{enumerate}
\item \cite{alesina2000redistributive}, which studies American states about
  their election and in order to find if any inequality measures could predict
  the share of public servants.
\item \cite{alt2014isn}, that describes the effect of accounting practices of
  EU countries over public employment.
\item \cite{aaskoven2015fiscal}, which analyzes the effect fiscal transparency
  on civil servants.
% \item \cite{schuster2013retreat} studies the retreat of OECD countries from the
%   sectors. The most notable quality of this paper is the data set they
%   collected across the countries and the years.
\end{enumerate}

\section{Theoretical models}

\cite{alesina2000redistributive} supposes that American cities use public
employment as a discreet mean for wealth redistributing: It channels resources
from middle class voters to disadvantaged citizens when an explicit
tax-transfer scheme would not find political support. In order to justify their
idea, they set the following theoretical framework: define a two periods
time-frame, with an election after the first period. There are two classes of
voters (\emph{middle} class and the \emph{poor}) and two contestants for the
government. Each candidate need the support of the middle class in order to win
the election. The challenge of the incumbent government is to know whether it
should start a public project to employ people from the poor class, at the risk
of losing political support from the middle class.

Define \(B\) as the benefit of a public project. This benefit can be thought of
the employment of the \emph{poor} to complete the project. Then restrict $B$ to
a discrete random variable with
\begin{align*}
  B =
  \left\{
    \begin{array}{ll}
    B_L & \mbox{with probability } 1-\theta \\
    B_H & \mbox{with probability } \theta
    \end{array}
  \right.
\end{align*}

where $0 < B_L < B_H$ and \(\theta\) is random variable taking either
\(\theta_L\) or \(\theta_H\) with \(0 < \theta_L < \theta_H < 1\). When
\(\theta=\theta_L\), it is more efficient to make a cash transfer than
implementing the project. Intuitively, $\theta$ is the risk of the
project. Moreover, the incumbent government observes the realisation of
\(\theta\) before deciding to implement a public project or not.

As there are two contestants for the government they also possess different
preferences: one supports the middle class and conduct the public project only
if \(\theta = \theta_H\), whereas the other favors the poor, leading the public
project for any value of \(\theta\) as long as the latter action does not
prevent the candidate from winning the next election.  Voters do not know which
type are the politicians, but they have prior believes: they are not completely
certain whom the candidates support. Moreover, being reelected is always
favored by the incumbent candidate as it maximizes her utility.

Under these conditions, \cite{alesina2000redistributive} shows there exists an
optimal decision for the incumbent government given $\theta$ and its
preferences. With the appropriate data, the paper observes that several
inequality measures are correlated with public employment shares, hence
supporting their view.

\cite{alt2014isn} and \cite{aaskoven2015fiscal} have a similar hypothesis: the
incumbent government will boost the share of public employment as election
dates are nearing in order to stay elected. They assert that the magnitude of
these changes can be explained by the degree of fiscal transparency of the
governments. Fiscal transparency is often measured measured by evaluating the
quality and frequency of financial reports from a country. They assume that
fiscal opacity allows governments to use unorthodox accounting methodology to
please political partners, financial markets and voters. It also allows them to
use use windfall revenues to employ more civil servants without voters
noticing, even though if these would prefer to have a tax cut or a cash
transfer. Furthermore, increasing the number public employees is a fast and
easy process for the incumbent government, because it usually does not require
a modification in the laws or the approval of the parliament.


\section{Statistical Analysis}

In practice, two challenges were encountered during the analysis: data
interpolation and statistical analysis.

\paragraph{Data interpolation}

The Economic Outlook dataset from the OECD exists in annual and quarterly
frequencies. Nevertheless, numerous variables are not measured quarterly and
quarterly interpolation of annual data is a reasonable choice in order to
retain information. However, economists often require for level variables
(i.e. measure with units) that the sum of quarterly data to be equal to the
annual value.  \cite{sax2014tempdisagg} proposes the Denton(-Chollette) method
as a decent choice for performing such a task. Heuristically, this method
(so-called temporal distribution or \emph{disaggregation}) solves the problem
by dividing and spreading the annual value into quarterly values, such that the
interpolation looks smooth in the end. This process can be thought as a smart
spline interpolation adjusted by a scaling factor. More sophisticated
methodology might use correlated quarterly variables in order to adjust the
annual ones, but this usually leads to over-fitting.

\paragraph{Data analysis}

The standard statistical methods in the literature are the regular multiple
linear regression. The cited references use the a common model. Assume that
$Y_{it}$ denotes the public employment rate (number of civil servants over
total labor force) for the $i$-th country and time $t$. Then $Y_{it}$ is fitted
as
\begin{align} \label{eq:reg}
  Y_{it} = X_{it}\beta + \eta_i + \tau_t + \varepsilon_{it}, \quad i \in \{1, \dots, n\},\ t \in \{1, \dots, T\},
\end{align}
where $X_{it} \in \mathbb{R}^{n \times p}$ is a matrix of explanatory and
control variables, $\beta \in \mathbb{R}^{p}$ is the regression coefficient,
$\eta_i$ is a country fixed-effect and $\tau_t$ is a time-fixed effect,
$\varepsilon_{it}$ are non-correlated centered gaussian random variables, $n$,
respectively $T$, is the number of countries, respectively, period of
observations. One weakness in the analysis of the literature is that
assumptions of the multiple regression are seldom checked. This is problematic
as for our data set the fitted values of $\varepsilon_{it}$ and
$\varepsilon_{i(t+1)}$ are highly correlated, contradicting the
assumption. Additionally, statistical significance is often reported with raw
$p$-values. Nonetheless, using these unprocessed $p$-values leads to a higher
rate of false positive. Best practice recommend to adjust these by controlling
the false discovery rate (see \cite{benjamini1995controlling}).

%%% Local Variables: ***
%%% mode:latex ***
%%% TeX-master: "semester_paper_sfs.tex"  ***
%%% End: ***
%%% reftex-default-bibliography: ("biblio.bib")
